{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4634c034-7f34-4f0a-a3a8-87143de0c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.chdir(sys.path[0]+'/search')\n",
    "\n",
    "from pacman import Directions\n",
    "from game import Agent\n",
    "import random\n",
    "import game\n",
    "import util\n",
    "\n",
    "class QLearnAgent(Agent):\n",
    "\n",
    "    # Constructor, called when we start running the\n",
    "    def __init__(self, alpha=0.3, epsilon=0.2, gamma=0.8, numTraining = 9990):\n",
    "        # alpha       - learning rate\n",
    "        # epsilon     - exploration rate\n",
    "        # gamma       - discount factor\n",
    "        # numTraining - number of training episodes\n",
    "        #\n",
    "        # These values are either passed from the command line or are\n",
    "        # set to the default values above. We need to create and set\n",
    "        # variables for them\n",
    "        self.alpha = float(alpha)\n",
    "        self.epsilon = float(epsilon)\n",
    "        self.gamma = float(gamma)\n",
    "        self.numTraining = int(numTraining)\n",
    "        # Count the number of games we have played\n",
    "        self.episodesSoFar = 0\n",
    "        # dictionary of Q-values\n",
    "        self.Q_values = dict()\n",
    "        # placeholder of the previous state\n",
    "        self.prev_state = None\n",
    "        # placeholder of the previous action\n",
    "        self.prev_action = None\n",
    "        # placeholder of the previous score\n",
    "        self.prev_score = None\n",
    "\n",
    "\n",
    "    # Accessor functions for the variable episodesSoFars controlling learning\n",
    "    def incrementEpisodesSoFar(self):\n",
    "        self.episodesSoFar += 1\n",
    "\n",
    "    def getEpisodesSoFar(self):\n",
    "        return self.episodesSoFar\n",
    "\n",
    "    def getNumTraining(self):\n",
    "        return self.numTraining\n",
    "\n",
    "    # Accessor functions for parameters\n",
    "    def setEpsilon(self, value):\n",
    "        self.epsilon = value\n",
    "\n",
    "    def getAlpha(self):\n",
    "        return self.alpha\n",
    "\n",
    "    def setAlpha(self, value):\n",
    "        self.alpha = value\n",
    "\n",
    "    def getGamma(self):\n",
    "        return self.gamma\n",
    "\n",
    "    def getMaxAttempts(self):\n",
    "        return self.maxAttempts\n",
    "\n",
    "\n",
    "    # getAction\n",
    "    #\n",
    "    # The main method required by the game. Called every time that\n",
    "    # Pacman is expected to move\n",
    "    def getAction(self, state, debug_mode=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Data about current state\n",
    "        \"\"\"\n",
    "        legal = state.getLegalPacmanActions()\n",
    "        if Directions.STOP in legal:\n",
    "            legal.remove(Directions.STOP)\n",
    "        pacman_position = state.getPacmanPosition()\n",
    "        ghost_positions = state.getGhostPositions()\n",
    "        food_locations = state.getFood()\n",
    "        # construct s'\n",
    "        curr_state = (str(legal), str(pacman_position), str(ghost_positions), str(food_locations))\n",
    "        if debug_mode:\n",
    "            print(\"Legal moves: \" + curr_state[0])\n",
    "            print(\"Pacman position: \" + curr_state[1])\n",
    "            print(\"Ghost positions: \" + curr_state[2])\n",
    "            print(\"Food locations: \")\n",
    "            print(curr_state[3])\n",
    "            print(\"Score: \" + str(state.getScore()) + \"\\n\")\n",
    "\n",
    "        # initialize Q-value\n",
    "        if state not in self.Q_values:\n",
    "            self.initialize_Q_values(state, legal)\n",
    "\n",
    "        # update Q-value\n",
    "        if self.prev_state != None:\n",
    "            self.update_Q_value(state)\n",
    "\n",
    "        # update placeholders\n",
    "        self.update_placeholders(state, legal)\n",
    "\n",
    "        return self.prev_action\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    training episodes: initialize Q-values\n",
    "    \"\"\"\n",
    "    def initialize_Q_values(self, state, legal):\n",
    "        self.Q_values[state] = dict()\n",
    "        for action in legal:\n",
    "            if action not in self.Q_values[state]:\n",
    "                self.Q_values[state][action] = 0.0\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    training episodes: update Q-value\n",
    "    \"\"\"\n",
    "    def update_Q_value(self, state, final_step=False):\n",
    "        # calculate R(s)\n",
    "        reward = state.getScore() - self.prev_score\n",
    "        # calculate max(Q(s', a'))\n",
    "        max_Q_value = 0.0\n",
    "        if not final_step:\n",
    "            max_Q_value = max(list(self.Q_values[state].values()))\n",
    "        # update Q(s, a)\n",
    "        self.Q_values[self.prev_state][self.prev_action] += (self.alpha * (reward + self.gamma * max_Q_value - self.Q_values[self.prev_state][self.prev_action]))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    update placeholders\n",
    "    \"\"\"\n",
    "    def update_placeholders(self, state, legal):\n",
    "        # register s' as s\n",
    "        self.prev_state = state\n",
    "        # register a' as a\n",
    "        self.prev_action = self.epsilon_greedy(state, legal)\n",
    "        # register as previous score\n",
    "        self.prev_score = state.getScore()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    action selection: epsilon-greedy\n",
    "    \"\"\"\n",
    "    def epsilon_greedy(self, state, legal):\n",
    "        # generate a random probability\n",
    "        probability = random.random()\n",
    "        # if probability is less than exploration rate: random action\n",
    "        if probability < self.epsilon:\n",
    "            random_action = random.choice(legal)\n",
    "            return random_action\n",
    "        # if probability is greater than exploration rate: max Q-value action\n",
    "        max_Q_action = None\n",
    "        for action in legal:\n",
    "            if max_Q_action == None:\n",
    "                max_Q_action = action\n",
    "            if self.Q_values[state][action] > self.Q_values[state][max_Q_action]:\n",
    "                max_Q_action = action\n",
    "        return max_Q_action\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Reset placeholder variables\n",
    "    \"\"\"\n",
    "    def reset_placeholders(self):\n",
    "        self.prev_state = None\n",
    "        self.prev_action = None\n",
    "        self.prev_score = None\n",
    "\n",
    "\n",
    "    # Handle the end of episodes\n",
    "    #\n",
    "    # This is called by the game after a win or a loss.\n",
    "    def final(self, state):\n",
    "\n",
    "        # update Q-value\n",
    "        if self.prev_state != None:\n",
    "            self.update_Q_value(state, final_step=True)\n",
    "\n",
    "        # reset placeholder variables\n",
    "        self.reset_placeholders()\n",
    "\n",
    "        # Keep track of the number of games played, and set learning\n",
    "        # parameters to zero when we are done with the pre-set number\n",
    "        # of training episodes\n",
    "        self.incrementEpisodesSoFar()\n",
    "        if self.getEpisodesSoFar() == self.getNumTraining():\n",
    "            msg = \"Training Done (turning off epsilon and alpha)\"\n",
    "            print(\"%s\\n%s\" % (msg,\"-\" * len(msg)))\n",
    "            self.setAlpha(0)\n",
    "            self.setEpsilon(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8779650-3f53-4705-9ce1-4b706d981b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done (turning off epsilon and alpha)\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pacman import runGames, loadAgent\n",
    "from pacman import Directions\n",
    "import pacmanAgents\n",
    "from util import Queue\n",
    "import textDisplay\n",
    "import game\n",
    "import layout\n",
    "import random\n",
    "import graphicsDisplay\n",
    "\n",
    "argumentos ={}\n",
    "pacman = QLearnAgent()\n",
    "ghostType = loadAgent('RandomGhost', True)\n",
    "textDisplay.SLEEP_TIME = 0\n",
    "argumentos['layout'] = layout.getLayout('smallClassic')\n",
    "argumentos['pacman'] = pacman\n",
    "argumentos['ghosts'] = [ghostType( i+1 ) for i in range( 2 )]\n",
    "argumentos['display'] = graphicsDisplay.PacmanGraphics(1, frameTime = 0)\n",
    "argumentos['numGames'] = 10000\n",
    "argumentos['numTraining'] = 9990\n",
    "argumentos['record'] = False\n",
    "argumentos['catchExceptions'] = False\n",
    "argumentos['timeout'] = 1\n",
    "\n",
    "res = runGames(**argumentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0495ed4-313e-44db-98bd-cd92c338293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-438.0\n",
      "-400.0\n",
      "-387.0\n",
      "-411.0\n",
      "-384.0\n",
      "-351.0\n",
      "-357.0\n",
      "-274.0\n",
      "-376.0\n",
      "-416.0\n"
     ]
    }
   ],
   "source": [
    "for a in res:\n",
    "    print(a.state.getScore())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecea526-866d-4d39-9fe3-7d8b18d033e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
