{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f25ac97-8a99-4dec-ba71-25370f29daa7",
   "metadata": {},
   "source": [
    "# MC886 - Projeto 3\n",
    "Aluno: Mateus Feitosa Olivi  RA: 222059"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf590409-9e25-422d-9057-f6f2839a40d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parte 1\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "&emsp; Nesta parte do projeto vou aplicar uma técnica de computação evolucionária para resolver o problema do Pac-man. O trabalho consiste em encontrar uma solução adequada para o problema, avaliando-o segundo diversos parâmetros.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d002eb20-eea4-4a7e-a80d-1f374c8504ab",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "&emsp; A primeira coisa que preciso fazer é definir um modelo para se aplicar o algoritmo evolucionario, isso é, um modelo que resolve o problema do Pac-man baseando-se em um conjunto de entradas que define um cromossomo. <br>\n",
    "&emsp; No tópico a seguir vou detalhar como achei o meu modelo:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e4ab88-7b63-4560-8fdc-ee8716a16630",
   "metadata": {},
   "source": [
    "### 1. Definição do modelo\n",
    "<p style=\"text-align: justify;\">\n",
    "&emsp; Antes de tudo vou importar as dependências para rodar o pacman:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23ee1177-d6fd-44b4-96d2-dc4bb032770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.chdir(sys.path[0]+'/search')\n",
    "\n",
    "from pacman import runGames, loadAgent\n",
    "from pacman import Directions\n",
    "import pacmanAgents\n",
    "from util import Queue\n",
    "import textDisplay\n",
    "import game\n",
    "import layout\n",
    "import random\n",
    "import graphicsDisplay\n",
    "\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c39aae-7f84-41dc-baab-98e783f81485",
   "metadata": {},
   "source": [
    "#### 1.2 Ideia inicial: \n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "&emsp; Para definir o modelo usei como inspiração inicial o GreedyAgent, esse agente está definido nos arquivos do pacman, mais precisamente no arquivo pacmanAgents.py, vamos dar uma olhada no que ele faz:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca74989c-66c1-45f2-90d7-c93aa3d4c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyAgent(game.Agent):\n",
    "    def __init__(self, evalFn=\"scoreEvaluation\"):\n",
    "        self.evaluationFunction = util.lookup(evalFn, globals())\n",
    "        assert self.evaluationFunction != None\n",
    "\n",
    "    def getAction(self, state):\n",
    "        # Generate candidate actions\n",
    "        legal = state.getLegalPacmanActions()\n",
    "        if Directions.STOP in legal: legal.remove(Directions.STOP)\n",
    "\n",
    "        successors = [(state.generateSuccessor(0, action), action) for action in legal]\n",
    "        scored = [(self.evaluationFunction(state), action) for state, action in successors]\n",
    "        bestScore = max(scored)[0]\n",
    "        bestActions = [pair[1] for pair in scored if pair[0] == bestScore]\n",
    "        return random.choice(bestActions)\n",
    "\n",
    "def scoreEvaluation(state):\n",
    "    return state.getScore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41252003-8526-4095-93e9-62ec00e4411e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "&emsp; Esse código é relativamente simples, no método getAction, inicialmente o agente verifica quais ações ele pode fazer, isso é, quais direção ele pode ir, desconsiderando a possibilidade do pacman ficar parado, para isso o código usa um método já implementado, que é o getLegalPacmanActions(). Após isso, para cada possível direção, o código gera os estados sucessores possíveis, utilizando o método generateSuccessor(). Por fim esse agente verifica qual desses estados tem o melhor score, utilizando a função scoreEvaluation, e então retorna qual é a melhor ação a ser executada para se obter o maior score. <br>\n",
    "&emsp; Mas note, esse agente é muito simplista, e não pode ser utilizado para se aplicar um algoritmo genético, porém posso modificar ele de tal forma a obter um agente em que poderei aplicar o algoritmo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00deeb8-11e8-4f76-9f47-831302dd35da",
   "metadata": {},
   "source": [
    "#### 1.3 O meu modelo\n",
    "<p style=\"text-align: justify;\">\n",
    "&emsp; No GreedyAgent, o estado é avaliado segundo o score que foi feito, porém isso não é necessariamente bom, já que as vezes o pacman deve fazer desviar de um fantasma, ou então prefirir comer uma capsula ao invés de comer uma comida, ou seja, no meu modelo a avaliação do estado não será baseado, exclusivamente, no score. <br>\n",
    "&emsp; Essa avaliação pode seguir a lógica de se obter algum bônus por fazer alguma ação positiva que não é contabilizada pelo score, ou seja, o pacman pode obter um bônus por se afastar de um fantasma, por estar perto de um fantasma assustado, por se aproximar de uma capsula, por consumir uma capsula, por consumir um fantasma assustado, por se aproximar de uma comida e por consumir uma comida. <br>\n",
    "&emsp; Um exemplo para essa lógica: se eu tiver um alto bônus por aproximar de uma comida e um baixo bônus por ficar longe dos fantasmas, o pacman poderá morrer tentando pegar uma comida, porém na situacão oposta, o pacman ira prefirir ficar distantes dos fantasmas do que consumir comidas. <br>\n",
    "&emsp; Esses bônus poderão ser regulados com pesos que serão dados a eles, esses pesos serão os parametros do meu modelo e determinará o grau de importancia para a escolha do melhor estado seguinte do pacman.<br>\n",
    "&emsp; Abaixo segue o modelo que fiz baseando-se nessa lógica:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "879dbcb4-ef40-48b6-8f83-cec94e3b1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartAgent(game.Agent):    \n",
    "    def __init__(self, pesos):\n",
    "        self.pesos = pesos\n",
    "        \n",
    "    def getAction(self, state):\n",
    "        legal = state.getLegalPacmanActions()\n",
    "        if Directions.STOP in legal: legal.remove(Directions.STOP)\n",
    "    \n",
    "        currentState = state\n",
    "        \n",
    "        successors = [(state.generateSuccessor(0, action), action) for action in legal]\n",
    "        evalueted =  [(self.evaluation(state, currentState), action) for state, action in successors]\n",
    "        bestEvaluation = max(evalueted)[0]\n",
    "        bestActions = [pair[1] for pair in evalueted if pair[0] == bestEvaluation]\n",
    "        \n",
    "        return random.choice(bestActions)\n",
    "        \n",
    "    def getNeighbors(self, pos, walls, visited):\n",
    "        c, l = pos\n",
    "        neighbors = []\n",
    "        \n",
    "        for i in range(-1,2,1):\n",
    "            for j in range(-1,2,1):\n",
    "                if(abs(i) != abs(j) and c+i < walls.width and c+i >= 0 and l+j < walls.height and l+j >= 0):\n",
    "                    if(walls[c+i][l+j] == False and visited[c+i][l+j] == 0):\n",
    "                        neighbors.append((c+i,l+j))             \n",
    "        return neighbors\n",
    "        \n",
    "    def bfsDistance(self, state, posIni, endPos = None, food = False):\n",
    "        queue = Queue()\n",
    "        \n",
    "        walls = state.getWalls()\n",
    "        if(food):\n",
    "            foods = state.getFood()\n",
    "            \n",
    "        visited = np.zeros((walls.width,walls.height))\n",
    "        visited[posIni[0]][posIni[1]] = 1\n",
    "                \n",
    "        queue.push((posIni, 1))\n",
    "        while(not queue.isEmpty()):\n",
    "            current = queue.pop()\n",
    "            pos = current[0]\n",
    "            stepsUntilNow = current[1]\n",
    "            \n",
    "            if(food == True):\n",
    "                if(foods[pos[0]][pos[1]] == True):\n",
    "                    return stepsUntilNow\n",
    "            else:\n",
    "                if(pos[0] == endPos[0] and pos[1] == endPos[1]):\n",
    "                    return stepsUntilNow\n",
    "    \n",
    "            visited[pos[0]][pos[1]] = 1\n",
    "            possibles = self.getNeighbors(pos,walls, visited)\n",
    "            for possibleMove in possibles:\n",
    "                queue.push((possibleMove, stepsUntilNow+1))\n",
    "        return -1\n",
    "    \n",
    "    def ghosts(self, state):\n",
    "        ghostsPos = state.getGhostPositions()\n",
    "        n_ghosts = len(ghostsPos)\n",
    "        \n",
    "        scared_timer = []\n",
    "        positionsNonScared = []\n",
    "        positionsScared = []\n",
    "        \n",
    "        for i in range(n_ghosts):\n",
    "            scared_timer.append(state.getGhostStates()[i].scaredTimer)\n",
    "            \n",
    "        for i in range(n_ghosts):\n",
    "            if(scared_timer[i] == 0):\n",
    "                positionsNonScared.append(np.ceil(ghostsPos[i]))\n",
    "            else:\n",
    "                positionsScared.append(np.ceil(ghostsPos[i]))\n",
    "            \n",
    "        return positionsScared, positionsNonScared\n",
    "    \n",
    "    def nearstElement(self, state, posElement, pacmanPos):\n",
    "        minDist = float('inf')\n",
    "        for pos in posElement:\n",
    "            dist = self.bfsDistance(state, pacmanPos, pos)\n",
    "            if(dist < minDist):\n",
    "                minDist = dist\n",
    "        return minDist\n",
    "            \n",
    "    def countScaredGhosts(self, state):\n",
    "        total=0\n",
    "        for ghost in state.getGhostStates():\n",
    "            if(ghost.scaredTimer !=0):\n",
    "                total+=1\n",
    "        return total\n",
    "    \n",
    "    def evaluation(self, state, currentState):\n",
    "        \n",
    "        p1 = self.pesos[0]   # peso relacionado à distancia do fantasma malvado \n",
    "        p2 = self.pesos[1]   # peso relacionado à distancia do fantasma assustado mais próximo\n",
    "        p3 = self.pesos[2]   # peso relacionado a comer um fantasma assustado\n",
    "        p4 = self.pesos[3]   # peso relacionado à distancia da comida mais próxima\n",
    "        p5 = self.pesos[4]   # peso relacionado a comer uma comida\n",
    "        p6 = self.pesos[5]   # peso relacionado à distancia da capsula mais próxima\n",
    "        p7 = self.pesos[6]   # peso relacionado a comer uma capsula\n",
    "        \n",
    "        score = state.getScore()\n",
    "        scaredGhosts, badGhosts = self.ghosts(state)\n",
    "        pacman = state.getPacmanPosition()\n",
    "        capsules = state.getCapsules()\n",
    "        \n",
    "        avaliacao = score\n",
    "        ################## Bad Ghost in next position  #################\n",
    "        if(len(badGhosts) > 0):\n",
    "            distBadGhost = self.nearstElement(state, badGhosts, pacman)\n",
    "            if(distBadGhost <= p1):\n",
    "                return float('-inf')\n",
    "            \n",
    "        ################## Nearst Scared Ghosts ####################\n",
    "        if(len(scaredGhosts) > 0):\n",
    "            distScaredGhosts = self.nearstElement(state, scaredGhosts, pacman)\n",
    "            avaliacao += p2*(1/distScaredGhosts)\n",
    "            \n",
    "        ############### Eat scared ghost bonus #################\n",
    "        numScaredCurrent = self.countScaredGhosts(currentState)\n",
    "        numScared = self.countScaredGhosts(state)\n",
    "        scaredDiff = numScaredCurrent - numScared\n",
    "        if(scaredDiff > 0):\n",
    "            avaliacao += p3 * scaredDiff\n",
    "            \n",
    "        ################ Nearst food ###################\n",
    "        nearestFood = self.bfsDistance(state, pacman, food = True)\n",
    "        avaliacao += p4*(1/nearestFood)\n",
    "        \n",
    "        ################ Eat food bonus ##################\n",
    "        numfood= state.getFood()\n",
    "        numFoodCurrent = currentState.getFood()\n",
    "        foodDiff = numFoodCurrent.count(True) - numfood.count(True)\n",
    "        avaliacao += p5*foodDiff\n",
    "        \n",
    "        ################# Nearst capsule ################\n",
    "        if(len(capsules) > 0):\n",
    "            distCapsule = self.nearstElement(state, capsules, pacman)\n",
    "            avaliacao += p6*(1/distCapsule)\n",
    "        \n",
    "        ################# Eat capsule bonus ##############\n",
    "        numcapsules = len(state.getCapsules())\n",
    "        numCapsulesCurrentState = len(currentState.getCapsules())\n",
    "        avaliacao += p7*(numCapsulesCurrentState - numcapsules)\n",
    "        \n",
    "        return avaliacao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47264478-928b-40ea-bcc7-8287f188f58a",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "&emsp; Note que esse agente faz o que planejei, no método getAction, inicialmente o agente verifica quais ações ele pode fazer, isso é, quais direção ele pode ir, desconsiderando a possibilidade do pacman ficar parado, para isso o código usa um método já implementado, que é o getLegalPacmanActions(). Após isso, para cada possível direção, o código gera os estados sucessores possíveis, utilizando o método generateSuccessor(). Por fim esse agente verifica qual desses estados tem uma melhor avaliação, utilizando o método evaluation. <br>\n",
    "&emsp; A avaliação de um estado é feita seguindo aquela lógica que já expliquei, abaixo definirei todos os fatores que serão usados para avaliar um estado:<br>\n",
    "\n",
    "1) Score: A avaliação do próximo estado começa com o score desse próximo estado.<br>\n",
    "2) Distancia ao fantasma mais próximo: Para a posição do pacman é calculada a distancia ao fantasma mais próximo, caso ele esteja a uma distância p1 do fantasma o score será avaliado como pior possivel e terá avaliação menos infinito. O Algoritmo genético se encarregará de descobrir qual valor de p1.<br>\n",
    "3) Distância ao fantasma assustado mais próximo: Para a posição do pacman é calculada a distância ao fantasma assustado mais próximo, então eu somo a avaliação do estado com um peso p2 multiplicado pelo inverso dessa distância, ou seja, menores distâncias a esses fantasmas levarão a uma melhor avaliação, o peso p2 regulará a importância de se aproximar desses fantasmas.<br>\n",
    "4) Comer fantasmas: É calculada a diferença entre o número de fantasmas assustados no próximo estado e do número de fantasmas assustados no estado atual, assim posso descobrir se foram consumidos fantamas, sabendo disso eu somo a avaliação do estado com um peso p3 multiplicado pelo número de fantasmas consumidos, esse peso p3 regulará a importância de consumir esses fantasmas .<br>\n",
    "5) Distância a comida mais próxima: Para a posição do pacman é calculada a distância a comida mais próxima, então eu somo a avaliação do estado com um peso p4 multiplicado pelo inverso dessa distância, ou seja, uma menor distância à comida mais próxima levará a uma melhor avaliação, o peso p4 regulará a importância de se aproximar da comida mais próxima.<br>\n",
    "6) Comer comidas: É calculada a diferença entre o número de comidas no próximo estado e do número de comidas no estado atual, assim posso descobrir se comidas foram consumidas, sabendo disso eu somo a avaliação do estado com um peso p5 multiplicado pelo número de comidas consumidas, esse peso p5 regulará a importância de consumir uma comida.<br>\n",
    "7) Distância a capsula mais próxima: Para a posição do pacman é calculada a distância a capsula mais próxima, então eu somo a avaliação do estado com um peso p6 multiplicado pelo inverso dessa distância, ou seja, uma menor distância à capsula mais próxima levará a uma melhor avaliação, o peso p6 regulará a importância de se aproximar das capsulas.<br>\n",
    "8) Comer capsula: É calculada a diferença entre o número de capsulas no próximo estado e do número de capsulas no estado atual, assim posso descobrir se capsulas foram consumidas, sabendo disso eu somo a avaliação do estado com um peso p7 multiplicado pelo número de capsulas consumidas, esse peso p7 regulará a importância de consumir uma capsula.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5b734b-8af8-42ea-8475-d9b3235e4e90",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "&emsp; Note que no meu código eu usei um bfs para calcular as distancias entre os elementos do tabuleiro, assim levarei em consideração as paredes.<br>\n",
    "&emsp; Os pesos p1, p2, p3, p4, p5, p6 e p7 serão descobertos aplicando um algoritmo genético, ou seja, um individuo será caracterizado por uma array na forma [p1,p2,p3,p4,p5,p6,p7]<br> \n",
    "&emsp; Agora com o agente pronto posso aplicar o algoritmo genético e achar o melhor conjunto de pesos para o executar o agente. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36529203-14ec-40b8-bc02-1afce5b8e64b",
   "metadata": {},
   "source": [
    "### 2. Algoritmo genético"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be31799-758d-4d1d-9a38-82e6db19586f",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "&emsp;Para o algoritmo genético irei utilizar a biblioteca geneticalgs, ela pode ser obtida através do pip, porém eu baixei os seus módulos do github oficial <a href=\"https://github.com/bobirdmi/genetic-algorithms\">link aqui</a>. <br>\n",
    "&emsp;Essa biblioteca faz tudo o que preciso, porém eu tive que modificá-la para obter o valor do maior e menor fitness em cada geração (o que não era feito por padrão), também adicionei um trecho de código para imprimir quando cada geração tiver sido gerada.<br>\n",
    "&emsp;Uma outra modificação que fiz foi quanto ao elitismo, em aula vimos que no elitismo em uma nova geração são gerados n-1 indivíduos novos e adicionado o indivíduo de melhor fitness da geração anterior, porém nessa biblioteca isso era diferente, nela, quando o elitismo era ativado, a nova geração tinha n indivíduos novos e também o indivíduo de melhor fitness da geração anterior, ou seja, a cada geração a população aumentava em 1 indivíduo, a modificação que fiz foi para que o elitismo ficasse igual o que foi visto em aula.<br>\n",
    "&emsp;A versão com todas essas modificações da biblioteca está na pasta geneticalgsmod.\n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b1b2d-7301-4076-8022-45e7fb7ce368",
   "metadata": {},
   "source": [
    "#### 2.1 Parâmetros da biblioteca\n",
    "Vou iniciar apresentando os parâmetros da biblioteca que eu vou usar:<br>\n",
    "1) fitness_func (function): A funcao de fitness será usada.<br>\n",
    "2) optim (str): Qual tipo de fitness será feito, isso é, se iremos maximizar a função de fitness (parâmetro 'max') ou se iremos minimiza-la (parâmetro 'min').<br>\n",
    "3) selection (str): Tipo de seleção que irá ser feita, \"rank\", \"roulette\" ou \"tournament\".<br>\n",
    "4) tournament_size (int): Define o tamanho do torneio no caso em que 'selection' == 'tournament'.<br>\n",
    "5) mut_prob (float): Probabilidade de ocorrer mutação.<br>\n",
    "6) mut_type (int): Nesse parâmetro se define quantos genes irão sofrer mutação.<br>\n",
    "7) cross_prob (float): Probabilidade de ocorrer crossover.<br>\n",
    "8) cross_type (int): Define o tipo de crossover, singlepoint (1), doublepoint (2), multipoint (> 2).<br>\n",
    "9) elitism (True, False): Habilita ou desabilita o elitismo.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30494173-2491-4c8e-9c64-abca6d8b455e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "&emsp; Durante o treinamento das populações irei deixar explicito como aplicarei esses parametros\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a50c09b-d80f-4016-91e3-27ebd0c279a0",
   "metadata": {},
   "source": [
    "### 3. Treinamento\n",
    "<p style=\"text-align: justify;\">\n",
    "&emsp; Agora vou fazer o treinamento incluindo os fantasmas para todos os layouts especificados, que são: smallClassic, mediumClassic e originalClassic.<br>\n",
    "&emsp;Primeiro vou definir os critérios e parâmetros que serão usados para fazer a evolução:<br>\n",
    "\n",
    "1) População inicial: Para aplicar o algoritmo genético irei utilizar uma população de 70 indivíduos, como tenho 7 genes em cada cromossomo, pensei que com 70 indivíduos eu terei uma variação de 10 valores diferentes para cada gene.<br>\n",
    "2) Critério de parada: Meu critério de parada será o número de gerações, no meu caso vou escolher 40 gerações.<br>\n",
    "3) Técnica de seleção: Como critério de seleção irei usar seleção por ranqueamento, como o problema do pacman está relacionado a pegar todas as comidas do tabuleiro com o maior score possível e baseando na maneira na qual eu modelei o problema, não acho que utilizar o ranqueamento me levará há um maxímo local.<br>\n",
    "4) Técnica de crossover: irei utilizar um crossover singlepoint.<br>\n",
    "5) Técnica de mutação: irei utilizar a técnica padrão da biblioteca que eu escolhi, o método aplicado é o seguinte: se escolhe o número n de genes que será aplicado a mutação e uma probabilidade p de ocorrer a mutação. Com esses dados o algoritmo irá transformar esses n genes em cadeias de bits e cada um desses bits é percorrido, então para cada um desses bits percorrido existe a probabilidade p desse bit ser invertido.<br>\n",
    "6) Método de substituição: Irei utilizar o elitismo, em uma nova geração a população terá tamanho n-1 e o melhor indíviduo da geração anterior será transferido para essa nova geração.<br>\n",
    "7) Taxa de mutação: Irei definir para a mutação ocorrer em no maxímo 1 gene e com probabilidade de inversão de cada bit de 10%, conforme descrito na Técnica de mutação.<br>\n",
    "8) Taxa de crossover: O singlepoint crossover irá ocorrer com probabilidade de 90%.<br>\n",
    "\n",
    "&emsp; Agora vou definir algumas funções auxiliares que utilizarei no treinamento:<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e81807-f07a-4d08-b3a8-b1215bbeeab2",
   "metadata": {},
   "source": [
    "#### 3.1 Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d7f9f1e-98da-4ddd-9dc7-725527cb0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runGame(pesos, olayout, graphics = False):\n",
    "    argumentos ={}\n",
    "    pacman = SmartAgent(pesos)\n",
    "    ghostType = loadAgent('DirectionalGhost', True)\n",
    "    textDisplay.SLEEP_TIME = 0\n",
    "    argumentos['layout'] = layout.getLayout(olayout)\n",
    "    argumentos['pacman'] = pacman\n",
    "    argumentos['ghosts'] = [ghostType( i+1 ) for i in range( 2 )]\n",
    "    argumentos['display'] = textDisplay.NullGraphics()\n",
    "    if(graphics):\n",
    "        argumentos['display'] = graphicsDisplay.PacmanGraphics(0.6, frameTime = 0)\n",
    "    argumentos['numGames'] = 1\n",
    "    argumentos['record'] = False\n",
    "    argumentos['catchExceptions'] = False\n",
    "    argumentos['timeout'] = 1\n",
    "    \n",
    "    res = runGames(**argumentos)\n",
    "    game = res[0] \n",
    "\n",
    "    return game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd4ae4-1104-4e59-a295-1471e2b7e86a",
   "metadata": {},
   "source": [
    "&emsp; Essa função roda o pacman usando o agente DirectionalGhost, que são os fantasmas que perseguem o pacman, além disso o parâmetro graphics define se usarei interface gráfico ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b285308-f81c-44c7-80fd-8a3d0e4b12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plotGraph(valores, titulo):\n",
    "    x1 = list(range(len(valores)))\n",
    "    plt.plot(x1, valores, 'o')\n",
    "    plt.xlabel('Gerações', fontsize = 12)\n",
    "    plt.ylabel('score', fontsize = 12)\n",
    "    plt.title(titulo,fontsize = 12 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6871e77b-305e-4e99-94ea-73d4167e4a3c",
   "metadata": {},
   "source": [
    "&emsp; Essa função é para plotar um gráfico de score pelo número de gerações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e3284-44f1-44be-929d-5986af1e1c5f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba551713-2f73-450a-a879-70ecfcf39598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
